\chapter{Introduction}

Over the past century, it has become increasingly apparent that Nature, at its most fundamental level, resists analogy with human experience. Quantum theory predicts behaviour which is not explained by any classical model. As a result, we have come to understand that certain intuitive beliefs concerning the potential capability of machines do not hold.  Given the ability to prepare, manipulate, and measure single quanta, there is very good evidence to suggest that we should be able to measure, communicate and compute using techniques which have no classical analogue. This new mode of operation promises enormous potential benefits in terms of speed, precision, and security.

Historically, light has played a central role both in creating and answering fundamental questions in physics. The question of the fundamental makeup of light was crucial to the development of quantum theory, and many experimental tests of the most surprising predictions of quantum mechanics were first performed using visible photons.  Moreover, many of the most significant modern technologies depend entirely on the ability to manipulate and measure visible or near-visible electromagnetic radiation. 

In order to implement new quantum technologies, we must choose a quantum system in which to encode information. Single photons can be readily generated and detected, and generally do not suffer from the detrimental effects of noise to the same extent as other quantum particles. As such, quantum optics represents a leading approach to the implementation of almost all proposed quantum technologies. 

Recently, it has been suggested that efficient and universal control over photonic quantum states could be implemented in a monolithic chip, enabling the technologies previously described. Some experimental evidence already exists to support this claim. However, in order to reach the ultimate goal of a tangible quantum advantage over classical machines, we must overcome a number of crucial challenges in photonics engineering. It is reasonable to expect that in the course of this technological development, we will, as a by-product, obtain tools which enable new science, and new understanding of quantum mechanics itself.

\section{Thesis outline}
Chapter \ref{chap:background} begins with a brief overview of quantum mechanics, entanglement, nonlocality, and prospective quantum technologies. We discuss the standard optical tool-kit in the context of quantum phenomena and quantum machines. We also discuss integrated quantum photonics. In chapter \ref{chap:cnot-mz}, we a reconfigurable integrated photonic chip incorporating two path-encoded qubits, and show that it performs with high fidelity across a large parameter space. In the course of this work we demonstrate two-qubit quantum state and process tomography, and violate a Bell inequality on-chip.  In chapter \ref{chap:delayed-choice}, we use this device to implement a variation on Wheeler's delayed-choice experiment, showing continuous morphing between wave-like and particle-like behaviour.  In chapter \ref{chap:random-chsh}, we consider the problem of obtaining nonlocal statistics, or certifying entanglement, without a shared reference frame. We introduce new techniques which facilitate this task, and experimentally demonstrate their feasibility. Chapter \ref{chap:quantum-chemistry} introduces a new algorithm for quantum chemistry on a quantum computer, and we use this algorithm to simulate the helium hydride ion. In chapter \ref{chap:hilbert-space-telescope}, we describe a multiphoton counting system using 16 detectors, and its application to the imaging of multiphoton quantum interference in Hilbert spaces of dimension $\sim50,000$. Chapter \ref{chap:discussion} concludes this thesis, with an outlook to future work.

% References
%\bibliographystyle{unsrt}
%\bibliography{main.bib}
